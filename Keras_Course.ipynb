{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras Course.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6FQ0dBBxbBJY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from random import randint\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.isdir('Properties_philly_Kraggle_v2.csv'):\n",
        "  print(os.listdir(\"/content\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-e1orw9kvC4r",
        "outputId": "5fcb57d5-7561-4380-e920-a9ab8c2f2f5e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['.config', 'Properties_philly_Kraggle_v2.csv', 'sample_data']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# philly_properties = np.genfromtxt('Properties_philly_Kraggle_v2.csv', delimiter=',')"
      ],
      "metadata": {
        "id": "tN5DSa_Cw2zF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read in table to Pandas Dataframe"
      ],
      "metadata": {
        "id": "-UTxTkYVVBud"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# df=pd.read_csv('Properties_philly_Kraggle_v2.csv', sep=',')\n",
        "df=pd.read_csv('Properties_philly_Kraggle_v2.csv', sep=',', index_col=False)\n",
        "df.dropna(inplace=True)\n",
        "df.reset_index()\n",
        "df.values"
      ],
      "metadata": {
        "id": "MTqidWjsxrkT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4ee1941-60a8-4b21-84fb-c92f4b2f6abd"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['2327 E SERGEANT ST ',\n",
              "        '2327 E SERGEANT ST , Philadelphia, PA 19125',\n",
              "        'September 13  2016', ..., '2', 'SingleFamily', '240,254.55'],\n",
              "       ['4466 TOLBUT ST ', '4466 TOLBUT ST , Philadelphia, PA 19136',\n",
              "        'August 2  2016', ..., '3', 'Townhouse', '150,937.50'],\n",
              "       ['134 E WALNUT LN ', '134 E WALNUT LN , Philadelphia, PA 19144',\n",
              "        'August 2  2016', ..., '3', 'SingleFamily', '225,483.33'],\n",
              "       ...,\n",
              "       ['653 N 33RD ST ', '653 N 33RD ST , Philadelphia, PA 19104',\n",
              "        'August 2  2016', ..., '5', 'MultiFamily2To4', '21,166.67'],\n",
              "       ['5423 WOODBINE AVE ',\n",
              "        '5423 WOODBINE AVE , Philadelphia, PA 19131', 'August 2  2016',\n",
              "        ..., '6', 'SingleFamily', '126,401.60'],\n",
              "       ['730 S CECIL ST ', '730 S CECIL ST , Philadelphia, PA 19143',\n",
              "        'August 2  2016', ..., '3', 'Townhouse', '38,900.00']],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove last index of n/a data"
      ],
      "metadata": {
        "id": "Qo9DsLHqVJ5N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix index after dropna\n",
        "df = df[:-1]"
      ],
      "metadata": {
        "id": "l9KMcmw_zDOw"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Drop columns that are not needed"
      ],
      "metadata": {
        "id": "Tb4mtqEAOlpU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['Address', 'Opening Bid', 'Book/Writ', 'OPA', 'Ward', 'Sheriff Cost', 'Advertising', 'Other', 'Record Deed', 'Zillow Estimate', 'Sale Date', 'Zillow Address', 'Attorney', 'Seller', 'Buyer'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "HZwvv8Kj1Qeg"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rename oddly formatted columns"
      ],
      "metadata": {
        "id": "s2mPlLdSVPNW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.rename(columns={'finished \\n(SqFt)':'SqFt', \n",
        "                   'Sale Price/bid price': 'Sale Price', \n",
        "                   'Zillow Address': 'Address', \n",
        "                   ' bedrooms ': 'bedrooms', \n",
        "                   ' Avg Walk&Transit score  ': 'Avg Walk&Transit score',\n",
        "                   ' Violent Crime Rate ': 'Violent Crime Rate',\n",
        "                   ' School Score  ': 'School Score',\n",
        "                   ' bathrooms ': 'bathrooms'}, inplace=True)"
      ],
      "metadata": {
        "id": "oWXl7LXj5hIz"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "z-W7yYA249hS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83c35c94-692a-4f72-a168-3f0beba0d9f3"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Sale Price', 'Postal Code', 'Water', 'PGW', 'Avg Walk&Transit score',\n",
              "       'Violent Crime Rate', 'School Score', 'Rent Estimate', 'taxAssessment',\n",
              "       'yearBuilt', 'SqFt', 'bathrooms', 'bedrooms', 'PropType',\n",
              "       'Average comps'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analyze Sale Prices\n",
        "And classify data into quantiles"
      ],
      "metadata": {
        "id": "GuC0Su_WzKER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prices = df['Sale Price']\n",
        "# prices.values\n",
        "prices = prices.to_numpy()\n",
        "prices_int = []\n",
        "for price in prices:\n",
        "  prices_int.append(int(price[1:].replace(',', '')))\n",
        "prices = np.array(prices_int)\n",
        "prices[1]"
      ],
      "metadata": {
        "id": "3x8Y7mHyn9Wh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "915053c1-fdb0-4698-8928-8cf3dbe1f618"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8500"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = [17.50, 13.50]\n",
        "plt.rcParams[\"figure.autolayout\"] = True\n",
        "\n",
        "prices_index = np.array(list(range(prices.size)))\n",
        "\n",
        "plt.title(\"Graph of Sale Price Data\")\n",
        "plt.plot(prices_index, prices, color=\"green\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MkhDGN5uphPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quartile_0 = min(prices) \n",
        "quartile_1 = np.quantile(prices, .25)\n",
        "quartile_2 = np.quantile(prices, .50)\n",
        "quartile_3 = np.quantile(prices, .75)\n",
        "quartile_4 = max(prices)\n",
        "print(quartile_0, quartile_1, quartile_2, quartile_3, quartile_4)"
      ],
      "metadata": {
        "id": "CEZaltl7p19F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de75f72f-d682-4942-c6bd-2f3ea8a7053e"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5200 20900.0 40000.0 80000.0 350000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Sales_price_category = []\n",
        "for price in prices:\n",
        "  if price < quartile_1:\n",
        "    Sales_price_category.append(float(0))\n",
        "  elif price < quartile_2:\n",
        "    Sales_price_category.append(float(1))\n",
        "  elif price < quartile_3:\n",
        "    Sales_price_category.append(float(2))\n",
        "  else:\n",
        "    Sales_price_category.append(float(3))\n",
        "Sales_price_category[-10:]"
      ],
      "metadata": {
        "id": "vKfxm3FOzkV8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a1682d9-90bc-404e-e841-ccaaee13cea4"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3.0, 2.0, 3.0, 2.0, 1.0, 3.0, 2.0, 2.0, 1.0, 3.0]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Sales Price Category'] = Sales_price_category\n",
        "df.drop(columns=['Sale Price'], inplace=True)\n",
        "df[-10:]"
      ],
      "metadata": {
        "id": "CmMRD36t19Pc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "outputId": "6942d6b4-6d8e-4484-ce7a-572718f5c6f4"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Postal Code     Water      PGW  Avg Walk&Transit score  \\\n",
              "604      19125.0   1008.58     0.00                   82.25   \n",
              "605      19135.0   2997.64  1339.18                   70.00   \n",
              "606      19120.0   4457.68    29.45                   79.88   \n",
              "607      19139.0    692.75   115.49                   80.08   \n",
              "608      19134.0    671.16     0.00                   71.25   \n",
              "609      19125.0   3043.45  1296.82                   82.25   \n",
              "610      19132.0   1274.85   556.48                   75.50   \n",
              "611      19139.0  53187.97  4930.07                   80.08   \n",
              "612      19104.0   1823.79   379.75                   81.79   \n",
              "613      19131.0   1937.32  7101.25                   65.75   \n",
              "\n",
              "     Violent Crime Rate  School Score Rent Estimate taxAssessment  yearBuilt  \\\n",
              "604                1.13         15.87      1,500.00    164,500.00     1918.0   \n",
              "605                0.52         21.53           975     82,400.00     1950.0   \n",
              "606                0.50         10.94      1,150.00    106,100.00     1950.0   \n",
              "607                1.54          3.34      1,050.00     32,400.00     1920.0   \n",
              "608                0.97         11.05      1,000.00     29,400.00     1910.0   \n",
              "609                1.13         15.87      1,350.00     74,700.00     1875.0   \n",
              "610                1.72          5.63      1,250.00     13,400.00     1936.0   \n",
              "611                1.54          3.34      1,100.00     43,900.00     1925.0   \n",
              "612                0.65         28.40      1,300.00     16,200.00     1935.0   \n",
              "613                0.29          8.34      1,450.00     65,700.00     1925.0   \n",
              "\n",
              "       SqFt bathrooms bedrooms         PropType Average comps  \\\n",
              "604  1050.0         1        4        Townhouse    186,845.45   \n",
              "605   992.0         1        2        Townhouse     75,117.89   \n",
              "606  1188.0         2        3        Townhouse     99,662.50   \n",
              "607  1209.0         1        3      Condominium     42,300.00   \n",
              "608   984.0         1        3        Townhouse     29,666.67   \n",
              "609  1120.0         2        3      Condominium    117,708.33   \n",
              "610  2288.0         1        5        Townhouse     72,625.00   \n",
              "611  1238.0         1        3        Townhouse     56,029.00   \n",
              "612  2315.0         4        5  MultiFamily2To4     21,166.67   \n",
              "613  3096.0         2        6     SingleFamily    126,401.60   \n",
              "\n",
              "     Sales Price Category  \n",
              "604                   3.0  \n",
              "605                   2.0  \n",
              "606                   3.0  \n",
              "607                   2.0  \n",
              "608                   1.0  \n",
              "609                   3.0  \n",
              "610                   2.0  \n",
              "611                   2.0  \n",
              "612                   1.0  \n",
              "613                   3.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d492c29d-e238-41c9-9aca-11fa8dcfbd2b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Postal Code</th>\n",
              "      <th>Water</th>\n",
              "      <th>PGW</th>\n",
              "      <th>Avg Walk&amp;Transit score</th>\n",
              "      <th>Violent Crime Rate</th>\n",
              "      <th>School Score</th>\n",
              "      <th>Rent Estimate</th>\n",
              "      <th>taxAssessment</th>\n",
              "      <th>yearBuilt</th>\n",
              "      <th>SqFt</th>\n",
              "      <th>bathrooms</th>\n",
              "      <th>bedrooms</th>\n",
              "      <th>PropType</th>\n",
              "      <th>Average comps</th>\n",
              "      <th>Sales Price Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>604</th>\n",
              "      <td>19125.0</td>\n",
              "      <td>1008.58</td>\n",
              "      <td>0.00</td>\n",
              "      <td>82.25</td>\n",
              "      <td>1.13</td>\n",
              "      <td>15.87</td>\n",
              "      <td>1,500.00</td>\n",
              "      <td>164,500.00</td>\n",
              "      <td>1918.0</td>\n",
              "      <td>1050.0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>Townhouse</td>\n",
              "      <td>186,845.45</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>605</th>\n",
              "      <td>19135.0</td>\n",
              "      <td>2997.64</td>\n",
              "      <td>1339.18</td>\n",
              "      <td>70.00</td>\n",
              "      <td>0.52</td>\n",
              "      <td>21.53</td>\n",
              "      <td>975</td>\n",
              "      <td>82,400.00</td>\n",
              "      <td>1950.0</td>\n",
              "      <td>992.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Townhouse</td>\n",
              "      <td>75,117.89</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>606</th>\n",
              "      <td>19120.0</td>\n",
              "      <td>4457.68</td>\n",
              "      <td>29.45</td>\n",
              "      <td>79.88</td>\n",
              "      <td>0.50</td>\n",
              "      <td>10.94</td>\n",
              "      <td>1,150.00</td>\n",
              "      <td>106,100.00</td>\n",
              "      <td>1950.0</td>\n",
              "      <td>1188.0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>Townhouse</td>\n",
              "      <td>99,662.50</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>607</th>\n",
              "      <td>19139.0</td>\n",
              "      <td>692.75</td>\n",
              "      <td>115.49</td>\n",
              "      <td>80.08</td>\n",
              "      <td>1.54</td>\n",
              "      <td>3.34</td>\n",
              "      <td>1,050.00</td>\n",
              "      <td>32,400.00</td>\n",
              "      <td>1920.0</td>\n",
              "      <td>1209.0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Condominium</td>\n",
              "      <td>42,300.00</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>608</th>\n",
              "      <td>19134.0</td>\n",
              "      <td>671.16</td>\n",
              "      <td>0.00</td>\n",
              "      <td>71.25</td>\n",
              "      <td>0.97</td>\n",
              "      <td>11.05</td>\n",
              "      <td>1,000.00</td>\n",
              "      <td>29,400.00</td>\n",
              "      <td>1910.0</td>\n",
              "      <td>984.0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Townhouse</td>\n",
              "      <td>29,666.67</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>609</th>\n",
              "      <td>19125.0</td>\n",
              "      <td>3043.45</td>\n",
              "      <td>1296.82</td>\n",
              "      <td>82.25</td>\n",
              "      <td>1.13</td>\n",
              "      <td>15.87</td>\n",
              "      <td>1,350.00</td>\n",
              "      <td>74,700.00</td>\n",
              "      <td>1875.0</td>\n",
              "      <td>1120.0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>Condominium</td>\n",
              "      <td>117,708.33</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>610</th>\n",
              "      <td>19132.0</td>\n",
              "      <td>1274.85</td>\n",
              "      <td>556.48</td>\n",
              "      <td>75.50</td>\n",
              "      <td>1.72</td>\n",
              "      <td>5.63</td>\n",
              "      <td>1,250.00</td>\n",
              "      <td>13,400.00</td>\n",
              "      <td>1936.0</td>\n",
              "      <td>2288.0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>Townhouse</td>\n",
              "      <td>72,625.00</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>611</th>\n",
              "      <td>19139.0</td>\n",
              "      <td>53187.97</td>\n",
              "      <td>4930.07</td>\n",
              "      <td>80.08</td>\n",
              "      <td>1.54</td>\n",
              "      <td>3.34</td>\n",
              "      <td>1,100.00</td>\n",
              "      <td>43,900.00</td>\n",
              "      <td>1925.0</td>\n",
              "      <td>1238.0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Townhouse</td>\n",
              "      <td>56,029.00</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>612</th>\n",
              "      <td>19104.0</td>\n",
              "      <td>1823.79</td>\n",
              "      <td>379.75</td>\n",
              "      <td>81.79</td>\n",
              "      <td>0.65</td>\n",
              "      <td>28.40</td>\n",
              "      <td>1,300.00</td>\n",
              "      <td>16,200.00</td>\n",
              "      <td>1935.0</td>\n",
              "      <td>2315.0</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>MultiFamily2To4</td>\n",
              "      <td>21,166.67</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>613</th>\n",
              "      <td>19131.0</td>\n",
              "      <td>1937.32</td>\n",
              "      <td>7101.25</td>\n",
              "      <td>65.75</td>\n",
              "      <td>0.29</td>\n",
              "      <td>8.34</td>\n",
              "      <td>1,450.00</td>\n",
              "      <td>65,700.00</td>\n",
              "      <td>1925.0</td>\n",
              "      <td>3096.0</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>SingleFamily</td>\n",
              "      <td>126,401.60</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d492c29d-e238-41c9-9aca-11fa8dcfbd2b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d492c29d-e238-41c9-9aca-11fa8dcfbd2b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d492c29d-e238-41c9-9aca-11fa8dcfbd2b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre process data for the Nerual Network"
      ],
      "metadata": {
        "id": "IlccLosQx4tF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# df.drop(columns=['Address', 'Attorney', 'Seller', 'Buyer'], inplace=True)"
      ],
      "metadata": {
        "id": "nng_QZ5JyCyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PropType = df['PropType']\n",
        "prop_types = set()\n",
        "for prop in PropType:\n",
        "  prop_types.add(prop)\n",
        "prop_types = list(prop_types)\n",
        "new_prop = list()\n",
        "for prop in PropType:\n",
        "  new_prop.append(float(prop_types.index(prop)))\n",
        "df['PropType'] = new_prop"
      ],
      "metadata": {
        "id": "igg6JyjdytX8"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Account for errror fields in the tables"
      ],
      "metadata": {
        "id": "tOJD7A0yQYFF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[df['bathrooms'] != ' -   ']\n",
        "df = df[df['bedrooms'] != ' -   ']\n",
        "df = df[df['Avg Walk&Transit score'] != ' -   ']\n",
        "df = df[df['Violent Crime Rate'] != ' -   ']\n",
        "df = df[df['School Score'] != ' -   ']\n",
        "df = df.astype({'bathrooms': float, 'bedrooms': float})"
      ],
      "metadata": {
        "id": "o4ahHwC1Q-Ck"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for column_name in ['Rent Estimate', 'taxAssessment', 'Average comps']:\n",
        "  new_col = list()\n",
        "  for cell in df[column_name]:\n",
        "    new_col.append(float(cell.replace(',', '')))\n",
        "  df[column_name] = new_col"
      ],
      "metadata": {
        "id": "fW1Onjan0m6V"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOed5vj6xG_I",
        "outputId": "0f7249c1-6f5a-4962-f775-589b98380790"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Postal Code               float64\n",
              "Water                     float64\n",
              "PGW                       float64\n",
              "Avg Walk&Transit score    float64\n",
              "Violent Crime Rate        float64\n",
              "School Score              float64\n",
              "Rent Estimate             float64\n",
              "taxAssessment             float64\n",
              "yearBuilt                 float64\n",
              "SqFt                      float64\n",
              "bathrooms                 float64\n",
              "bedrooms                  float64\n",
              "PropType                  float64\n",
              "Average comps             float64\n",
              "Sales Price Category      float64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.sample(frac = 1)\n",
        "train_samples = df[:500].drop(columns=['Sales Price Category'])\n",
        "train_labels = df[:500]['Sales Price Category']\n",
        "test_samples = df[500:].drop(columns=['Sales Price Category'])\n",
        "test_labels = df[500:]['Sales Price Category']"
      ],
      "metadata": {
        "id": "JtexpbCF4vY1"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_samples"
      ],
      "metadata": {
        "id": "8WQamPm56YQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_samples = train_samples.to_numpy()\n",
        "train_labels = train_labels.to_numpy()\n",
        "test_samples = test_samples.to_numpy()\n",
        "test_labels = test_labels.to_numpy()"
      ],
      "metadata": {
        "id": "DN2Krj1S4jOu"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_samples.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPsLMb76nYmT",
        "outputId": "bba7f5a8-6d95-4f2c-c5d9-827d961e9c83"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float64')"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building the neural network model"
      ],
      "metadata": {
        "id": "02JtzPBR8RpJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = None"
      ],
      "metadata": {
        "id": "b3q5-TOf7bBH"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import categorical_crossentropy"
      ],
      "metadata": {
        "id": "YFzH785v8WmL"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Dense(units=16, input_shape=(14,), activation='relu'),\n",
        "    Dense(units=32, activation='relu'),\n",
        "    Dense(units=4, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "XjzcN7Rx8j8U"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9gGeJts-jk4",
        "outputId": "317973b1-c3b6-40e3-f8ae-f330fc108724"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 16)                240       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 32)                544       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 4)                 132       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 916\n",
            "Trainable params: 916\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "mG3ZP7g2-xkt"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x=train_samples,\n",
        "          y=train_labels, validation_split=0.1,\n",
        "          batch_size=10,\n",
        "          epochs=200,\n",
        "          shuffle=True,\n",
        "          verbose=2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfg_XWXV-zfU",
        "outputId": "fe196607-052b-41d3-bd07-3cca4cbb783a"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "45/45 - 1s - loss: 3819.7134 - accuracy: 0.2667 - val_loss: 2305.0569 - val_accuracy: 0.2400 - 841ms/epoch - 19ms/step\n",
            "Epoch 2/200\n",
            "45/45 - 0s - loss: 1410.9448 - accuracy: 0.2911 - val_loss: 663.0961 - val_accuracy: 0.3400 - 84ms/epoch - 2ms/step\n",
            "Epoch 3/200\n",
            "45/45 - 0s - loss: 813.6852 - accuracy: 0.2711 - val_loss: 562.4999 - val_accuracy: 0.4200 - 79ms/epoch - 2ms/step\n",
            "Epoch 4/200\n",
            "45/45 - 0s - loss: 697.4105 - accuracy: 0.3111 - val_loss: 502.1662 - val_accuracy: 0.4600 - 80ms/epoch - 2ms/step\n",
            "Epoch 5/200\n",
            "45/45 - 0s - loss: 648.6060 - accuracy: 0.3244 - val_loss: 495.1388 - val_accuracy: 0.3400 - 85ms/epoch - 2ms/step\n",
            "Epoch 6/200\n",
            "45/45 - 0s - loss: 615.0458 - accuracy: 0.3311 - val_loss: 437.5821 - val_accuracy: 0.3800 - 87ms/epoch - 2ms/step\n",
            "Epoch 7/200\n",
            "45/45 - 0s - loss: 581.7440 - accuracy: 0.3400 - val_loss: 416.8485 - val_accuracy: 0.4400 - 105ms/epoch - 2ms/step\n",
            "Epoch 8/200\n",
            "45/45 - 0s - loss: 554.0734 - accuracy: 0.3422 - val_loss: 412.0222 - val_accuracy: 0.4400 - 105ms/epoch - 2ms/step\n",
            "Epoch 9/200\n",
            "45/45 - 0s - loss: 534.6822 - accuracy: 0.3467 - val_loss: 374.2389 - val_accuracy: 0.4600 - 89ms/epoch - 2ms/step\n",
            "Epoch 10/200\n",
            "45/45 - 0s - loss: 516.8296 - accuracy: 0.3622 - val_loss: 355.4240 - val_accuracy: 0.4800 - 100ms/epoch - 2ms/step\n",
            "Epoch 11/200\n",
            "45/45 - 0s - loss: 489.5610 - accuracy: 0.3667 - val_loss: 345.0041 - val_accuracy: 0.4800 - 93ms/epoch - 2ms/step\n",
            "Epoch 12/200\n",
            "45/45 - 0s - loss: 469.8950 - accuracy: 0.3489 - val_loss: 328.2661 - val_accuracy: 0.4800 - 98ms/epoch - 2ms/step\n",
            "Epoch 13/200\n",
            "45/45 - 0s - loss: 446.5702 - accuracy: 0.3622 - val_loss: 318.9219 - val_accuracy: 0.5000 - 94ms/epoch - 2ms/step\n",
            "Epoch 14/200\n",
            "45/45 - 0s - loss: 423.8657 - accuracy: 0.3667 - val_loss: 296.4654 - val_accuracy: 0.5000 - 92ms/epoch - 2ms/step\n",
            "Epoch 15/200\n",
            "45/45 - 0s - loss: 407.5855 - accuracy: 0.3756 - val_loss: 294.6432 - val_accuracy: 0.5200 - 76ms/epoch - 2ms/step\n",
            "Epoch 16/200\n",
            "45/45 - 0s - loss: 397.6685 - accuracy: 0.4044 - val_loss: 282.5996 - val_accuracy: 0.5200 - 106ms/epoch - 2ms/step\n",
            "Epoch 17/200\n",
            "45/45 - 0s - loss: 387.4096 - accuracy: 0.4267 - val_loss: 269.9656 - val_accuracy: 0.5800 - 100ms/epoch - 2ms/step\n",
            "Epoch 18/200\n",
            "45/45 - 0s - loss: 376.5665 - accuracy: 0.4133 - val_loss: 268.8340 - val_accuracy: 0.5000 - 90ms/epoch - 2ms/step\n",
            "Epoch 19/200\n",
            "45/45 - 0s - loss: 371.2039 - accuracy: 0.4356 - val_loss: 305.3105 - val_accuracy: 0.4800 - 82ms/epoch - 2ms/step\n",
            "Epoch 20/200\n",
            "45/45 - 0s - loss: 372.4012 - accuracy: 0.4356 - val_loss: 260.1679 - val_accuracy: 0.5200 - 78ms/epoch - 2ms/step\n",
            "Epoch 21/200\n",
            "45/45 - 0s - loss: 357.1785 - accuracy: 0.4400 - val_loss: 250.1530 - val_accuracy: 0.5600 - 82ms/epoch - 2ms/step\n",
            "Epoch 22/200\n",
            "45/45 - 0s - loss: 349.2474 - accuracy: 0.4511 - val_loss: 248.8281 - val_accuracy: 0.5200 - 79ms/epoch - 2ms/step\n",
            "Epoch 23/200\n",
            "45/45 - 0s - loss: 341.7820 - accuracy: 0.4467 - val_loss: 252.5751 - val_accuracy: 0.5200 - 92ms/epoch - 2ms/step\n",
            "Epoch 24/200\n",
            "45/45 - 0s - loss: 341.2896 - accuracy: 0.4356 - val_loss: 244.2487 - val_accuracy: 0.5400 - 84ms/epoch - 2ms/step\n",
            "Epoch 25/200\n",
            "45/45 - 0s - loss: 331.1886 - accuracy: 0.4533 - val_loss: 240.9965 - val_accuracy: 0.5800 - 78ms/epoch - 2ms/step\n",
            "Epoch 26/200\n",
            "45/45 - 0s - loss: 323.1125 - accuracy: 0.4533 - val_loss: 233.7238 - val_accuracy: 0.5400 - 83ms/epoch - 2ms/step\n",
            "Epoch 27/200\n",
            "45/45 - 0s - loss: 318.4397 - accuracy: 0.4489 - val_loss: 232.1516 - val_accuracy: 0.5800 - 77ms/epoch - 2ms/step\n",
            "Epoch 28/200\n",
            "45/45 - 0s - loss: 313.6496 - accuracy: 0.4800 - val_loss: 225.9689 - val_accuracy: 0.5800 - 83ms/epoch - 2ms/step\n",
            "Epoch 29/200\n",
            "45/45 - 0s - loss: 306.0705 - accuracy: 0.4622 - val_loss: 228.3506 - val_accuracy: 0.4800 - 84ms/epoch - 2ms/step\n",
            "Epoch 30/200\n",
            "45/45 - 0s - loss: 307.0040 - accuracy: 0.4622 - val_loss: 230.2207 - val_accuracy: 0.5200 - 108ms/epoch - 2ms/step\n",
            "Epoch 31/200\n",
            "45/45 - 0s - loss: 297.2897 - accuracy: 0.4622 - val_loss: 221.8196 - val_accuracy: 0.5000 - 81ms/epoch - 2ms/step\n",
            "Epoch 32/200\n",
            "45/45 - 0s - loss: 292.5822 - accuracy: 0.4889 - val_loss: 214.2551 - val_accuracy: 0.5600 - 77ms/epoch - 2ms/step\n",
            "Epoch 33/200\n",
            "45/45 - 0s - loss: 295.6234 - accuracy: 0.4756 - val_loss: 210.7414 - val_accuracy: 0.5800 - 93ms/epoch - 2ms/step\n",
            "Epoch 34/200\n",
            "45/45 - 0s - loss: 282.2760 - accuracy: 0.4644 - val_loss: 206.9874 - val_accuracy: 0.5600 - 98ms/epoch - 2ms/step\n",
            "Epoch 35/200\n",
            "45/45 - 0s - loss: 276.4034 - accuracy: 0.4733 - val_loss: 197.0404 - val_accuracy: 0.5800 - 74ms/epoch - 2ms/step\n",
            "Epoch 36/200\n",
            "45/45 - 0s - loss: 274.0084 - accuracy: 0.4733 - val_loss: 209.7323 - val_accuracy: 0.5200 - 85ms/epoch - 2ms/step\n",
            "Epoch 37/200\n",
            "45/45 - 0s - loss: 262.1311 - accuracy: 0.4778 - val_loss: 202.9269 - val_accuracy: 0.5200 - 80ms/epoch - 2ms/step\n",
            "Epoch 38/200\n",
            "45/45 - 0s - loss: 252.6287 - accuracy: 0.5000 - val_loss: 184.3673 - val_accuracy: 0.5800 - 95ms/epoch - 2ms/step\n",
            "Epoch 39/200\n",
            "45/45 - 0s - loss: 254.3150 - accuracy: 0.4889 - val_loss: 174.3931 - val_accuracy: 0.5400 - 83ms/epoch - 2ms/step\n",
            "Epoch 40/200\n",
            "45/45 - 0s - loss: 245.9066 - accuracy: 0.5000 - val_loss: 169.2018 - val_accuracy: 0.5600 - 76ms/epoch - 2ms/step\n",
            "Epoch 41/200\n",
            "45/45 - 0s - loss: 238.3033 - accuracy: 0.5044 - val_loss: 166.0988 - val_accuracy: 0.5600 - 89ms/epoch - 2ms/step\n",
            "Epoch 42/200\n",
            "45/45 - 0s - loss: 235.1921 - accuracy: 0.5044 - val_loss: 159.7485 - val_accuracy: 0.6000 - 98ms/epoch - 2ms/step\n",
            "Epoch 43/200\n",
            "45/45 - 0s - loss: 229.0862 - accuracy: 0.4978 - val_loss: 163.3784 - val_accuracy: 0.4600 - 85ms/epoch - 2ms/step\n",
            "Epoch 44/200\n",
            "45/45 - 0s - loss: 228.5750 - accuracy: 0.4889 - val_loss: 162.0481 - val_accuracy: 0.5400 - 81ms/epoch - 2ms/step\n",
            "Epoch 45/200\n",
            "45/45 - 0s - loss: 222.8190 - accuracy: 0.4733 - val_loss: 156.3446 - val_accuracy: 0.5200 - 95ms/epoch - 2ms/step\n",
            "Epoch 46/200\n",
            "45/45 - 0s - loss: 217.2910 - accuracy: 0.5000 - val_loss: 146.9314 - val_accuracy: 0.5200 - 84ms/epoch - 2ms/step\n",
            "Epoch 47/200\n",
            "45/45 - 0s - loss: 212.1804 - accuracy: 0.4978 - val_loss: 169.9193 - val_accuracy: 0.5600 - 79ms/epoch - 2ms/step\n",
            "Epoch 48/200\n",
            "45/45 - 0s - loss: 215.6199 - accuracy: 0.4978 - val_loss: 138.0361 - val_accuracy: 0.4600 - 99ms/epoch - 2ms/step\n",
            "Epoch 49/200\n",
            "45/45 - 0s - loss: 207.1468 - accuracy: 0.4756 - val_loss: 132.5804 - val_accuracy: 0.5000 - 98ms/epoch - 2ms/step\n",
            "Epoch 50/200\n",
            "45/45 - 0s - loss: 200.1747 - accuracy: 0.4822 - val_loss: 141.7387 - val_accuracy: 0.5800 - 95ms/epoch - 2ms/step\n",
            "Epoch 51/200\n",
            "45/45 - 0s - loss: 200.5904 - accuracy: 0.5133 - val_loss: 142.6221 - val_accuracy: 0.5800 - 95ms/epoch - 2ms/step\n",
            "Epoch 52/200\n",
            "45/45 - 0s - loss: 188.8923 - accuracy: 0.4933 - val_loss: 130.4316 - val_accuracy: 0.5000 - 110ms/epoch - 2ms/step\n",
            "Epoch 53/200\n",
            "45/45 - 0s - loss: 185.9995 - accuracy: 0.4867 - val_loss: 129.7678 - val_accuracy: 0.4800 - 99ms/epoch - 2ms/step\n",
            "Epoch 54/200\n",
            "45/45 - 0s - loss: 195.8694 - accuracy: 0.4867 - val_loss: 142.8562 - val_accuracy: 0.5800 - 78ms/epoch - 2ms/step\n",
            "Epoch 55/200\n",
            "45/45 - 0s - loss: 183.5935 - accuracy: 0.5067 - val_loss: 118.7410 - val_accuracy: 0.5600 - 95ms/epoch - 2ms/step\n",
            "Epoch 56/200\n",
            "45/45 - 0s - loss: 185.6580 - accuracy: 0.4956 - val_loss: 123.3869 - val_accuracy: 0.5000 - 92ms/epoch - 2ms/step\n",
            "Epoch 57/200\n",
            "45/45 - 0s - loss: 188.7317 - accuracy: 0.5089 - val_loss: 122.7191 - val_accuracy: 0.5600 - 82ms/epoch - 2ms/step\n",
            "Epoch 58/200\n",
            "45/45 - 0s - loss: 177.3445 - accuracy: 0.5000 - val_loss: 118.5769 - val_accuracy: 0.5400 - 79ms/epoch - 2ms/step\n",
            "Epoch 59/200\n",
            "45/45 - 0s - loss: 175.0198 - accuracy: 0.5156 - val_loss: 110.5854 - val_accuracy: 0.5000 - 77ms/epoch - 2ms/step\n",
            "Epoch 60/200\n",
            "45/45 - 0s - loss: 171.4271 - accuracy: 0.4933 - val_loss: 107.5647 - val_accuracy: 0.4800 - 83ms/epoch - 2ms/step\n",
            "Epoch 61/200\n",
            "45/45 - 0s - loss: 164.9227 - accuracy: 0.5200 - val_loss: 120.1174 - val_accuracy: 0.5200 - 91ms/epoch - 2ms/step\n",
            "Epoch 62/200\n",
            "45/45 - 0s - loss: 170.0447 - accuracy: 0.5200 - val_loss: 108.7020 - val_accuracy: 0.5800 - 85ms/epoch - 2ms/step\n",
            "Epoch 63/200\n",
            "45/45 - 0s - loss: 161.7655 - accuracy: 0.4889 - val_loss: 109.0873 - val_accuracy: 0.5200 - 98ms/epoch - 2ms/step\n",
            "Epoch 64/200\n",
            "45/45 - 0s - loss: 160.5863 - accuracy: 0.5111 - val_loss: 112.1990 - val_accuracy: 0.5400 - 81ms/epoch - 2ms/step\n",
            "Epoch 65/200\n",
            "45/45 - 0s - loss: 158.1654 - accuracy: 0.5244 - val_loss: 103.1660 - val_accuracy: 0.5600 - 78ms/epoch - 2ms/step\n",
            "Epoch 66/200\n",
            "45/45 - 0s - loss: 159.9325 - accuracy: 0.4911 - val_loss: 108.8434 - val_accuracy: 0.5800 - 81ms/epoch - 2ms/step\n",
            "Epoch 67/200\n",
            "45/45 - 0s - loss: 153.1551 - accuracy: 0.5089 - val_loss: 108.5851 - val_accuracy: 0.5600 - 78ms/epoch - 2ms/step\n",
            "Epoch 68/200\n",
            "45/45 - 0s - loss: 151.4045 - accuracy: 0.5022 - val_loss: 97.3388 - val_accuracy: 0.6200 - 95ms/epoch - 2ms/step\n",
            "Epoch 69/200\n",
            "45/45 - 0s - loss: 153.8716 - accuracy: 0.5244 - val_loss: 91.8645 - val_accuracy: 0.5000 - 95ms/epoch - 2ms/step\n",
            "Epoch 70/200\n",
            "45/45 - 0s - loss: 149.1431 - accuracy: 0.5200 - val_loss: 84.1615 - val_accuracy: 0.5400 - 80ms/epoch - 2ms/step\n",
            "Epoch 71/200\n",
            "45/45 - 0s - loss: 147.1757 - accuracy: 0.5333 - val_loss: 139.7602 - val_accuracy: 0.4400 - 85ms/epoch - 2ms/step\n",
            "Epoch 72/200\n",
            "45/45 - 0s - loss: 145.1033 - accuracy: 0.5000 - val_loss: 80.1986 - val_accuracy: 0.5800 - 96ms/epoch - 2ms/step\n",
            "Epoch 73/200\n",
            "45/45 - 0s - loss: 137.7634 - accuracy: 0.5222 - val_loss: 106.7847 - val_accuracy: 0.5000 - 80ms/epoch - 2ms/step\n",
            "Epoch 74/200\n",
            "45/45 - 0s - loss: 140.4677 - accuracy: 0.5156 - val_loss: 78.6709 - val_accuracy: 0.5400 - 91ms/epoch - 2ms/step\n",
            "Epoch 75/200\n",
            "45/45 - 0s - loss: 141.1431 - accuracy: 0.5222 - val_loss: 90.7485 - val_accuracy: 0.5400 - 84ms/epoch - 2ms/step\n",
            "Epoch 76/200\n",
            "45/45 - 0s - loss: 137.5460 - accuracy: 0.5000 - val_loss: 89.5233 - val_accuracy: 0.5800 - 79ms/epoch - 2ms/step\n",
            "Epoch 77/200\n",
            "45/45 - 0s - loss: 139.2269 - accuracy: 0.5111 - val_loss: 105.9551 - val_accuracy: 0.5400 - 81ms/epoch - 2ms/step\n",
            "Epoch 78/200\n",
            "45/45 - 0s - loss: 141.2520 - accuracy: 0.5156 - val_loss: 74.8557 - val_accuracy: 0.5400 - 80ms/epoch - 2ms/step\n",
            "Epoch 79/200\n",
            "45/45 - 0s - loss: 130.4965 - accuracy: 0.5089 - val_loss: 82.9480 - val_accuracy: 0.5800 - 78ms/epoch - 2ms/step\n",
            "Epoch 80/200\n",
            "45/45 - 0s - loss: 129.8141 - accuracy: 0.5267 - val_loss: 74.3575 - val_accuracy: 0.5200 - 76ms/epoch - 2ms/step\n",
            "Epoch 81/200\n",
            "45/45 - 0s - loss: 124.6252 - accuracy: 0.5289 - val_loss: 96.1470 - val_accuracy: 0.5000 - 97ms/epoch - 2ms/step\n",
            "Epoch 82/200\n",
            "45/45 - 0s - loss: 128.1677 - accuracy: 0.5111 - val_loss: 79.4802 - val_accuracy: 0.5600 - 84ms/epoch - 2ms/step\n",
            "Epoch 83/200\n",
            "45/45 - 0s - loss: 126.2664 - accuracy: 0.5222 - val_loss: 66.9125 - val_accuracy: 0.6400 - 78ms/epoch - 2ms/step\n",
            "Epoch 84/200\n",
            "45/45 - 0s - loss: 124.2610 - accuracy: 0.5200 - val_loss: 74.1703 - val_accuracy: 0.5600 - 78ms/epoch - 2ms/step\n",
            "Epoch 85/200\n",
            "45/45 - 0s - loss: 119.4939 - accuracy: 0.5244 - val_loss: 65.6694 - val_accuracy: 0.5200 - 84ms/epoch - 2ms/step\n",
            "Epoch 86/200\n",
            "45/45 - 0s - loss: 118.9450 - accuracy: 0.5178 - val_loss: 72.2052 - val_accuracy: 0.5000 - 95ms/epoch - 2ms/step\n",
            "Epoch 87/200\n",
            "45/45 - 0s - loss: 121.0652 - accuracy: 0.4978 - val_loss: 77.7836 - val_accuracy: 0.5200 - 97ms/epoch - 2ms/step\n",
            "Epoch 88/200\n",
            "45/45 - 0s - loss: 118.1534 - accuracy: 0.5044 - val_loss: 66.1196 - val_accuracy: 0.5600 - 98ms/epoch - 2ms/step\n",
            "Epoch 89/200\n",
            "45/45 - 0s - loss: 117.1610 - accuracy: 0.5356 - val_loss: 60.3892 - val_accuracy: 0.6400 - 93ms/epoch - 2ms/step\n",
            "Epoch 90/200\n",
            "45/45 - 0s - loss: 111.8537 - accuracy: 0.5111 - val_loss: 67.4724 - val_accuracy: 0.5400 - 97ms/epoch - 2ms/step\n",
            "Epoch 91/200\n",
            "45/45 - 0s - loss: 109.7391 - accuracy: 0.5200 - val_loss: 79.2108 - val_accuracy: 0.5600 - 78ms/epoch - 2ms/step\n",
            "Epoch 92/200\n",
            "45/45 - 0s - loss: 111.8201 - accuracy: 0.5156 - val_loss: 60.7287 - val_accuracy: 0.5200 - 93ms/epoch - 2ms/step\n",
            "Epoch 93/200\n",
            "45/45 - 0s - loss: 106.6734 - accuracy: 0.5089 - val_loss: 60.2467 - val_accuracy: 0.5600 - 87ms/epoch - 2ms/step\n",
            "Epoch 94/200\n",
            "45/45 - 0s - loss: 105.1415 - accuracy: 0.4733 - val_loss: 71.0156 - val_accuracy: 0.6000 - 76ms/epoch - 2ms/step\n",
            "Epoch 95/200\n",
            "45/45 - 0s - loss: 106.4785 - accuracy: 0.5067 - val_loss: 57.3691 - val_accuracy: 0.5600 - 83ms/epoch - 2ms/step\n",
            "Epoch 96/200\n",
            "45/45 - 0s - loss: 109.4682 - accuracy: 0.5067 - val_loss: 72.7316 - val_accuracy: 0.4200 - 97ms/epoch - 2ms/step\n",
            "Epoch 97/200\n",
            "45/45 - 0s - loss: 106.4678 - accuracy: 0.4911 - val_loss: 55.4772 - val_accuracy: 0.6400 - 87ms/epoch - 2ms/step\n",
            "Epoch 98/200\n",
            "45/45 - 0s - loss: 98.0115 - accuracy: 0.5222 - val_loss: 51.9776 - val_accuracy: 0.6000 - 79ms/epoch - 2ms/step\n",
            "Epoch 99/200\n",
            "45/45 - 0s - loss: 101.2383 - accuracy: 0.4911 - val_loss: 47.2557 - val_accuracy: 0.6600 - 89ms/epoch - 2ms/step\n",
            "Epoch 100/200\n",
            "45/45 - 0s - loss: 107.6516 - accuracy: 0.4867 - val_loss: 49.1061 - val_accuracy: 0.5600 - 96ms/epoch - 2ms/step\n",
            "Epoch 101/200\n",
            "45/45 - 0s - loss: 97.1066 - accuracy: 0.5178 - val_loss: 51.5000 - val_accuracy: 0.5600 - 90ms/epoch - 2ms/step\n",
            "Epoch 102/200\n",
            "45/45 - 0s - loss: 104.1635 - accuracy: 0.4822 - val_loss: 66.6345 - val_accuracy: 0.5400 - 76ms/epoch - 2ms/step\n",
            "Epoch 103/200\n",
            "45/45 - 0s - loss: 101.9877 - accuracy: 0.4844 - val_loss: 47.6893 - val_accuracy: 0.5200 - 99ms/epoch - 2ms/step\n",
            "Epoch 104/200\n",
            "45/45 - 0s - loss: 90.1663 - accuracy: 0.5133 - val_loss: 47.0891 - val_accuracy: 0.6200 - 78ms/epoch - 2ms/step\n",
            "Epoch 105/200\n",
            "45/45 - 0s - loss: 90.8914 - accuracy: 0.5022 - val_loss: 43.9373 - val_accuracy: 0.6000 - 101ms/epoch - 2ms/step\n",
            "Epoch 106/200\n",
            "45/45 - 0s - loss: 93.5721 - accuracy: 0.4911 - val_loss: 45.8936 - val_accuracy: 0.5600 - 81ms/epoch - 2ms/step\n",
            "Epoch 107/200\n",
            "45/45 - 0s - loss: 89.2933 - accuracy: 0.5111 - val_loss: 67.0403 - val_accuracy: 0.5400 - 94ms/epoch - 2ms/step\n",
            "Epoch 108/200\n",
            "45/45 - 0s - loss: 89.1829 - accuracy: 0.4911 - val_loss: 63.9750 - val_accuracy: 0.5800 - 85ms/epoch - 2ms/step\n",
            "Epoch 109/200\n",
            "45/45 - 0s - loss: 85.0153 - accuracy: 0.5178 - val_loss: 58.9385 - val_accuracy: 0.5400 - 85ms/epoch - 2ms/step\n",
            "Epoch 110/200\n",
            "45/45 - 0s - loss: 88.5797 - accuracy: 0.5067 - val_loss: 49.4765 - val_accuracy: 0.5800 - 81ms/epoch - 2ms/step\n",
            "Epoch 111/200\n",
            "45/45 - 0s - loss: 86.2083 - accuracy: 0.4956 - val_loss: 45.0926 - val_accuracy: 0.6200 - 103ms/epoch - 2ms/step\n",
            "Epoch 112/200\n",
            "45/45 - 0s - loss: 78.8280 - accuracy: 0.5089 - val_loss: 53.2490 - val_accuracy: 0.4800 - 82ms/epoch - 2ms/step\n",
            "Epoch 113/200\n",
            "45/45 - 0s - loss: 83.2273 - accuracy: 0.5067 - val_loss: 56.0630 - val_accuracy: 0.5200 - 95ms/epoch - 2ms/step\n",
            "Epoch 114/200\n",
            "45/45 - 0s - loss: 78.6510 - accuracy: 0.5022 - val_loss: 49.6939 - val_accuracy: 0.5400 - 81ms/epoch - 2ms/step\n",
            "Epoch 115/200\n",
            "45/45 - 0s - loss: 79.6884 - accuracy: 0.5089 - val_loss: 56.1851 - val_accuracy: 0.5800 - 80ms/epoch - 2ms/step\n",
            "Epoch 116/200\n",
            "45/45 - 0s - loss: 81.5205 - accuracy: 0.4489 - val_loss: 49.3689 - val_accuracy: 0.5800 - 87ms/epoch - 2ms/step\n",
            "Epoch 117/200\n",
            "45/45 - 0s - loss: 76.7942 - accuracy: 0.5044 - val_loss: 52.2989 - val_accuracy: 0.5800 - 97ms/epoch - 2ms/step\n",
            "Epoch 118/200\n",
            "45/45 - 0s - loss: 72.7550 - accuracy: 0.4956 - val_loss: 50.4054 - val_accuracy: 0.6000 - 84ms/epoch - 2ms/step\n",
            "Epoch 119/200\n",
            "45/45 - 0s - loss: 78.5697 - accuracy: 0.5000 - val_loss: 45.7991 - val_accuracy: 0.5800 - 102ms/epoch - 2ms/step\n",
            "Epoch 120/200\n",
            "45/45 - 0s - loss: 81.4485 - accuracy: 0.5044 - val_loss: 68.6523 - val_accuracy: 0.4200 - 78ms/epoch - 2ms/step\n",
            "Epoch 121/200\n",
            "45/45 - 0s - loss: 72.8586 - accuracy: 0.4956 - val_loss: 56.1344 - val_accuracy: 0.5400 - 85ms/epoch - 2ms/step\n",
            "Epoch 122/200\n",
            "45/45 - 0s - loss: 73.2942 - accuracy: 0.5111 - val_loss: 48.5214 - val_accuracy: 0.5800 - 92ms/epoch - 2ms/step\n",
            "Epoch 123/200\n",
            "45/45 - 0s - loss: 70.8791 - accuracy: 0.5022 - val_loss: 45.8414 - val_accuracy: 0.5000 - 76ms/epoch - 2ms/step\n",
            "Epoch 124/200\n",
            "45/45 - 0s - loss: 73.7995 - accuracy: 0.5267 - val_loss: 72.5375 - val_accuracy: 0.6000 - 78ms/epoch - 2ms/step\n",
            "Epoch 125/200\n",
            "45/45 - 0s - loss: 78.4504 - accuracy: 0.4844 - val_loss: 50.0866 - val_accuracy: 0.5200 - 102ms/epoch - 2ms/step\n",
            "Epoch 126/200\n",
            "45/45 - 0s - loss: 67.4037 - accuracy: 0.5111 - val_loss: 52.6011 - val_accuracy: 0.5600 - 87ms/epoch - 2ms/step\n",
            "Epoch 127/200\n",
            "45/45 - 0s - loss: 68.7754 - accuracy: 0.4978 - val_loss: 52.1039 - val_accuracy: 0.3800 - 91ms/epoch - 2ms/step\n",
            "Epoch 128/200\n",
            "45/45 - 0s - loss: 74.4224 - accuracy: 0.4800 - val_loss: 46.8162 - val_accuracy: 0.5200 - 84ms/epoch - 2ms/step\n",
            "Epoch 129/200\n",
            "45/45 - 0s - loss: 71.0248 - accuracy: 0.5000 - val_loss: 48.8341 - val_accuracy: 0.5400 - 80ms/epoch - 2ms/step\n",
            "Epoch 130/200\n",
            "45/45 - 0s - loss: 67.6689 - accuracy: 0.5044 - val_loss: 41.7575 - val_accuracy: 0.4800 - 107ms/epoch - 2ms/step\n",
            "Epoch 131/200\n",
            "45/45 - 0s - loss: 70.5071 - accuracy: 0.4933 - val_loss: 56.5379 - val_accuracy: 0.5400 - 80ms/epoch - 2ms/step\n",
            "Epoch 132/200\n",
            "45/45 - 0s - loss: 76.9841 - accuracy: 0.5133 - val_loss: 64.3992 - val_accuracy: 0.5400 - 80ms/epoch - 2ms/step\n",
            "Epoch 133/200\n",
            "45/45 - 0s - loss: 68.1188 - accuracy: 0.5044 - val_loss: 41.9270 - val_accuracy: 0.5200 - 84ms/epoch - 2ms/step\n",
            "Epoch 134/200\n",
            "45/45 - 0s - loss: 71.7816 - accuracy: 0.4644 - val_loss: 41.9255 - val_accuracy: 0.5200 - 78ms/epoch - 2ms/step\n",
            "Epoch 135/200\n",
            "45/45 - 0s - loss: 63.1781 - accuracy: 0.5067 - val_loss: 41.0758 - val_accuracy: 0.5000 - 76ms/epoch - 2ms/step\n",
            "Epoch 136/200\n",
            "45/45 - 0s - loss: 66.0902 - accuracy: 0.5000 - val_loss: 41.2521 - val_accuracy: 0.5600 - 93ms/epoch - 2ms/step\n",
            "Epoch 137/200\n",
            "45/45 - 0s - loss: 62.8270 - accuracy: 0.5178 - val_loss: 42.3441 - val_accuracy: 0.5400 - 83ms/epoch - 2ms/step\n",
            "Epoch 138/200\n",
            "45/45 - 0s - loss: 63.5811 - accuracy: 0.4889 - val_loss: 49.8700 - val_accuracy: 0.5800 - 92ms/epoch - 2ms/step\n",
            "Epoch 139/200\n",
            "45/45 - 0s - loss: 59.6510 - accuracy: 0.5156 - val_loss: 46.5345 - val_accuracy: 0.5800 - 77ms/epoch - 2ms/step\n",
            "Epoch 140/200\n",
            "45/45 - 0s - loss: 59.6178 - accuracy: 0.5067 - val_loss: 38.0738 - val_accuracy: 0.5600 - 94ms/epoch - 2ms/step\n",
            "Epoch 141/200\n",
            "45/45 - 0s - loss: 58.9101 - accuracy: 0.5133 - val_loss: 35.8170 - val_accuracy: 0.5400 - 117ms/epoch - 3ms/step\n",
            "Epoch 142/200\n",
            "45/45 - 0s - loss: 61.9674 - accuracy: 0.5000 - val_loss: 36.4199 - val_accuracy: 0.5200 - 75ms/epoch - 2ms/step\n",
            "Epoch 143/200\n",
            "45/45 - 0s - loss: 59.6930 - accuracy: 0.4756 - val_loss: 35.3943 - val_accuracy: 0.5400 - 75ms/epoch - 2ms/step\n",
            "Epoch 144/200\n",
            "45/45 - 0s - loss: 60.2862 - accuracy: 0.5044 - val_loss: 53.6124 - val_accuracy: 0.5800 - 84ms/epoch - 2ms/step\n",
            "Epoch 145/200\n",
            "45/45 - 0s - loss: 60.6030 - accuracy: 0.5156 - val_loss: 35.2996 - val_accuracy: 0.5600 - 78ms/epoch - 2ms/step\n",
            "Epoch 146/200\n",
            "45/45 - 0s - loss: 57.4927 - accuracy: 0.4956 - val_loss: 37.5170 - val_accuracy: 0.5200 - 86ms/epoch - 2ms/step\n",
            "Epoch 147/200\n",
            "45/45 - 0s - loss: 58.5624 - accuracy: 0.4956 - val_loss: 37.3332 - val_accuracy: 0.6200 - 90ms/epoch - 2ms/step\n",
            "Epoch 148/200\n",
            "45/45 - 0s - loss: 56.5419 - accuracy: 0.5000 - val_loss: 41.1233 - val_accuracy: 0.6600 - 78ms/epoch - 2ms/step\n",
            "Epoch 149/200\n",
            "45/45 - 0s - loss: 59.2574 - accuracy: 0.5178 - val_loss: 45.7017 - val_accuracy: 0.6000 - 87ms/epoch - 2ms/step\n",
            "Epoch 150/200\n",
            "45/45 - 0s - loss: 57.4089 - accuracy: 0.4822 - val_loss: 35.8647 - val_accuracy: 0.5800 - 97ms/epoch - 2ms/step\n",
            "Epoch 151/200\n",
            "45/45 - 0s - loss: 51.8045 - accuracy: 0.4911 - val_loss: 38.5339 - val_accuracy: 0.5400 - 94ms/epoch - 2ms/step\n",
            "Epoch 152/200\n",
            "45/45 - 0s - loss: 54.2093 - accuracy: 0.5044 - val_loss: 39.3927 - val_accuracy: 0.6000 - 81ms/epoch - 2ms/step\n",
            "Epoch 153/200\n",
            "45/45 - 0s - loss: 54.8894 - accuracy: 0.5178 - val_loss: 38.5676 - val_accuracy: 0.6200 - 80ms/epoch - 2ms/step\n",
            "Epoch 154/200\n",
            "45/45 - 0s - loss: 51.3468 - accuracy: 0.5022 - val_loss: 50.6054 - val_accuracy: 0.6000 - 79ms/epoch - 2ms/step\n",
            "Epoch 155/200\n",
            "45/45 - 0s - loss: 52.4259 - accuracy: 0.5000 - val_loss: 32.7415 - val_accuracy: 0.5600 - 80ms/epoch - 2ms/step\n",
            "Epoch 156/200\n",
            "45/45 - 0s - loss: 51.3055 - accuracy: 0.5022 - val_loss: 38.8779 - val_accuracy: 0.6400 - 80ms/epoch - 2ms/step\n",
            "Epoch 157/200\n",
            "45/45 - 0s - loss: 55.0960 - accuracy: 0.5222 - val_loss: 36.3517 - val_accuracy: 0.5800 - 76ms/epoch - 2ms/step\n",
            "Epoch 158/200\n",
            "45/45 - 0s - loss: 49.8886 - accuracy: 0.5067 - val_loss: 32.2792 - val_accuracy: 0.5400 - 82ms/epoch - 2ms/step\n",
            "Epoch 159/200\n",
            "45/45 - 0s - loss: 54.8206 - accuracy: 0.5200 - val_loss: 36.1082 - val_accuracy: 0.4400 - 96ms/epoch - 2ms/step\n",
            "Epoch 160/200\n",
            "45/45 - 0s - loss: 58.9414 - accuracy: 0.4844 - val_loss: 44.4389 - val_accuracy: 0.5800 - 84ms/epoch - 2ms/step\n",
            "Epoch 161/200\n",
            "45/45 - 0s - loss: 49.9797 - accuracy: 0.4978 - val_loss: 41.4904 - val_accuracy: 0.5600 - 100ms/epoch - 2ms/step\n",
            "Epoch 162/200\n",
            "45/45 - 0s - loss: 46.8262 - accuracy: 0.5000 - val_loss: 38.9744 - val_accuracy: 0.5600 - 76ms/epoch - 2ms/step\n",
            "Epoch 163/200\n",
            "45/45 - 0s - loss: 57.7900 - accuracy: 0.4733 - val_loss: 38.7590 - val_accuracy: 0.6400 - 83ms/epoch - 2ms/step\n",
            "Epoch 164/200\n",
            "45/45 - 0s - loss: 59.5600 - accuracy: 0.4778 - val_loss: 37.7937 - val_accuracy: 0.3800 - 108ms/epoch - 2ms/step\n",
            "Epoch 165/200\n",
            "45/45 - 0s - loss: 51.7866 - accuracy: 0.5044 - val_loss: 56.1604 - val_accuracy: 0.6000 - 78ms/epoch - 2ms/step\n",
            "Epoch 166/200\n",
            "45/45 - 0s - loss: 51.3310 - accuracy: 0.4867 - val_loss: 31.2025 - val_accuracy: 0.5600 - 77ms/epoch - 2ms/step\n",
            "Epoch 167/200\n",
            "45/45 - 0s - loss: 44.1881 - accuracy: 0.5267 - val_loss: 33.3844 - val_accuracy: 0.6800 - 97ms/epoch - 2ms/step\n",
            "Epoch 168/200\n",
            "45/45 - 0s - loss: 47.6469 - accuracy: 0.5044 - val_loss: 36.2258 - val_accuracy: 0.6000 - 100ms/epoch - 2ms/step\n",
            "Epoch 169/200\n",
            "45/45 - 0s - loss: 49.9279 - accuracy: 0.4778 - val_loss: 30.7963 - val_accuracy: 0.5600 - 96ms/epoch - 2ms/step\n",
            "Epoch 170/200\n",
            "45/45 - 0s - loss: 45.7042 - accuracy: 0.5311 - val_loss: 37.1619 - val_accuracy: 0.5400 - 79ms/epoch - 2ms/step\n",
            "Epoch 171/200\n",
            "45/45 - 0s - loss: 47.4203 - accuracy: 0.4600 - val_loss: 31.7709 - val_accuracy: 0.4800 - 100ms/epoch - 2ms/step\n",
            "Epoch 172/200\n",
            "45/45 - 0s - loss: 50.0025 - accuracy: 0.4644 - val_loss: 35.7311 - val_accuracy: 0.6200 - 100ms/epoch - 2ms/step\n",
            "Epoch 173/200\n",
            "45/45 - 0s - loss: 47.4602 - accuracy: 0.5000 - val_loss: 31.5808 - val_accuracy: 0.6000 - 84ms/epoch - 2ms/step\n",
            "Epoch 174/200\n",
            "45/45 - 0s - loss: 48.7121 - accuracy: 0.4667 - val_loss: 34.0558 - val_accuracy: 0.5200 - 87ms/epoch - 2ms/step\n",
            "Epoch 175/200\n",
            "45/45 - 0s - loss: 43.7618 - accuracy: 0.4844 - val_loss: 38.6899 - val_accuracy: 0.6200 - 90ms/epoch - 2ms/step\n",
            "Epoch 176/200\n",
            "45/45 - 0s - loss: 45.6599 - accuracy: 0.5022 - val_loss: 34.8416 - val_accuracy: 0.6400 - 76ms/epoch - 2ms/step\n",
            "Epoch 177/200\n",
            "45/45 - 0s - loss: 50.5527 - accuracy: 0.4933 - val_loss: 35.1193 - val_accuracy: 0.6000 - 82ms/epoch - 2ms/step\n",
            "Epoch 178/200\n",
            "45/45 - 0s - loss: 43.8418 - accuracy: 0.5044 - val_loss: 36.7975 - val_accuracy: 0.5800 - 91ms/epoch - 2ms/step\n",
            "Epoch 179/200\n",
            "45/45 - 0s - loss: 46.3300 - accuracy: 0.4800 - val_loss: 37.3052 - val_accuracy: 0.5800 - 79ms/epoch - 2ms/step\n",
            "Epoch 180/200\n",
            "45/45 - 0s - loss: 46.4604 - accuracy: 0.5089 - val_loss: 36.3416 - val_accuracy: 0.6000 - 84ms/epoch - 2ms/step\n",
            "Epoch 181/200\n",
            "45/45 - 0s - loss: 43.2967 - accuracy: 0.5111 - val_loss: 28.4774 - val_accuracy: 0.5600 - 76ms/epoch - 2ms/step\n",
            "Epoch 182/200\n",
            "45/45 - 0s - loss: 40.5251 - accuracy: 0.4911 - val_loss: 27.5047 - val_accuracy: 0.5600 - 92ms/epoch - 2ms/step\n",
            "Epoch 183/200\n",
            "45/45 - 0s - loss: 47.4962 - accuracy: 0.4911 - val_loss: 40.7355 - val_accuracy: 0.6200 - 75ms/epoch - 2ms/step\n",
            "Epoch 184/200\n",
            "45/45 - 0s - loss: 43.4992 - accuracy: 0.5067 - val_loss: 28.2826 - val_accuracy: 0.6000 - 79ms/epoch - 2ms/step\n",
            "Epoch 185/200\n",
            "45/45 - 0s - loss: 41.8832 - accuracy: 0.5111 - val_loss: 38.4319 - val_accuracy: 0.5400 - 98ms/epoch - 2ms/step\n",
            "Epoch 186/200\n",
            "45/45 - 0s - loss: 40.9045 - accuracy: 0.4956 - val_loss: 28.1639 - val_accuracy: 0.6000 - 88ms/epoch - 2ms/step\n",
            "Epoch 187/200\n",
            "45/45 - 0s - loss: 54.6538 - accuracy: 0.4756 - val_loss: 49.2090 - val_accuracy: 0.3600 - 79ms/epoch - 2ms/step\n",
            "Epoch 188/200\n",
            "45/45 - 0s - loss: 47.4104 - accuracy: 0.4889 - val_loss: 29.6871 - val_accuracy: 0.4600 - 77ms/epoch - 2ms/step\n",
            "Epoch 189/200\n",
            "45/45 - 0s - loss: 47.1807 - accuracy: 0.5111 - val_loss: 34.7607 - val_accuracy: 0.6000 - 101ms/epoch - 2ms/step\n",
            "Epoch 190/200\n",
            "45/45 - 0s - loss: 44.5363 - accuracy: 0.4644 - val_loss: 35.2827 - val_accuracy: 0.6400 - 79ms/epoch - 2ms/step\n",
            "Epoch 191/200\n",
            "45/45 - 0s - loss: 41.3640 - accuracy: 0.5178 - val_loss: 32.9768 - val_accuracy: 0.4000 - 92ms/epoch - 2ms/step\n",
            "Epoch 192/200\n",
            "45/45 - 0s - loss: 40.2166 - accuracy: 0.5022 - val_loss: 28.9275 - val_accuracy: 0.5400 - 89ms/epoch - 2ms/step\n",
            "Epoch 193/200\n",
            "45/45 - 0s - loss: 39.3914 - accuracy: 0.5111 - val_loss: 28.1817 - val_accuracy: 0.6000 - 80ms/epoch - 2ms/step\n",
            "Epoch 194/200\n",
            "45/45 - 0s - loss: 37.5115 - accuracy: 0.5178 - val_loss: 30.8238 - val_accuracy: 0.6000 - 79ms/epoch - 2ms/step\n",
            "Epoch 195/200\n",
            "45/45 - 0s - loss: 38.0178 - accuracy: 0.5200 - val_loss: 32.8945 - val_accuracy: 0.6600 - 94ms/epoch - 2ms/step\n",
            "Epoch 196/200\n",
            "45/45 - 0s - loss: 40.0395 - accuracy: 0.5133 - val_loss: 32.1033 - val_accuracy: 0.6400 - 86ms/epoch - 2ms/step\n",
            "Epoch 197/200\n",
            "45/45 - 0s - loss: 37.9826 - accuracy: 0.5000 - val_loss: 25.0148 - val_accuracy: 0.5800 - 80ms/epoch - 2ms/step\n",
            "Epoch 198/200\n",
            "45/45 - 0s - loss: 38.4406 - accuracy: 0.4911 - val_loss: 28.9873 - val_accuracy: 0.5200 - 93ms/epoch - 2ms/step\n",
            "Epoch 199/200\n",
            "45/45 - 0s - loss: 45.5454 - accuracy: 0.4667 - val_loss: 32.8707 - val_accuracy: 0.4600 - 82ms/epoch - 2ms/step\n",
            "Epoch 200/200\n",
            "45/45 - 0s - loss: 37.1575 - accuracy: 0.5089 - val_loss: 34.5730 - val_accuracy: 0.6400 - 81ms/epoch - 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcf8f002d50>"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(x=test_samples, batch_size=10, verbose=1) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLKSD1cDqaIi",
        "outputId": "b0e4626f-1cc7-40b5-dbd0-c2a3e5f89955"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in predictions:\n",
        "    print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8QY88q0raUQ",
        "outputId": "81ad4d09-dd9d-49ff-b7ad-6147f64c4a65"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.9209437e-23 0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
            "[3.4329188e-13 0.0000000e+00 1.0000000e+00 9.4134917e-33]\n",
            "[1.7044647e-24 9.9534082e-01 4.6591237e-03 0.0000000e+00]\n",
            "[0.000000e+00 0.000000e+00 6.328928e-30 1.000000e+00]\n",
            "[0.000000e+00 2.296235e-10 1.000000e+00 0.000000e+00]\n",
            "[2.0006111e-19 0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
            "[0.6547844  0.         0.34521565 0.        ]\n",
            "[1. 0. 0. 0.]\n",
            "[1. 0. 0. 0.]\n",
            "[3.5643016e-10 0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
            "[9.9998569e-01 2.6422262e-33 1.4257644e-05 0.0000000e+00]\n",
            "[9.9969363e-01 1.0395137e-36 3.0639410e-04 0.0000000e+00]\n",
            "[0. 0. 0. 1.]\n",
            "[1. 0. 0. 0.]\n",
            "[4.5203248e-21 0.0000000e+00 1.0000000e+00 1.3471043e-32]\n",
            "[1.0000000e+00 4.4561642e-17 1.1328860e-13 0.0000000e+00]\n",
            "[0. 0. 0. 1.]\n",
            "[0. 0. 0. 1.]\n",
            "[4.021773e-09 0.000000e+00 1.000000e+00 0.000000e+00]\n",
            "[1. 0. 0. 0.]\n",
            "[1.0000000e+00 4.5341371e-30 1.0351761e-17 0.0000000e+00]\n",
            "[0.00273223 0.         0.99726784 0.        ]\n",
            "[9.9995816e-01 2.3841750e-18 4.1802210e-05 0.0000000e+00]\n",
            "[1.2730662e-05 0.0000000e+00 9.9998724e-01 0.0000000e+00]\n",
            "[1. 0. 0. 0.]\n",
            "[1.0000000e+00 8.4854977e-16 0.0000000e+00 0.0000000e+00]\n",
            "[1.2659007e-20 6.0724602e-16 1.0000000e+00 0.0000000e+00]\n",
            "[0. 0. 1. 0.]\n",
            "[1.0000000e+00 2.7549856e-23 1.4344535e-20 0.0000000e+00]\n",
            "[1. 0. 0. 0.]\n",
            "[0. 0. 0. 1.]\n",
            "[2.8782836e-29 0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
            "[0.99600005 0.0017345  0.00226553 0.        ]\n",
            "[0. 0. 0. 1.]\n",
            "[6.6337093e-06 1.7386200e-27 9.9999332e-01 0.0000000e+00]\n",
            "[0. 0. 0. 1.]\n",
            "[7.4580191e-13 3.4407966e-14 1.0000000e+00 0.0000000e+00]\n",
            "[9.999608e-01 0.000000e+00 3.919302e-05 0.000000e+00]\n",
            "[0.0000000e+00 0.0000000e+00 6.2641103e-27 1.0000000e+00]\n",
            "[0. 0. 0. 1.]\n",
            "[7.080484e-11 0.000000e+00 1.000000e+00 0.000000e+00]\n",
            "[0. 0. 0. 1.]\n",
            "[9.0377545e-03 4.2063593e-27 9.9096221e-01 0.0000000e+00]\n",
            "[0. 0. 1. 0.]\n",
            "[0. 0. 1. 0.]\n",
            "[1. 0. 0. 0.]\n",
            "[6.4522152e-05 2.2015115e-35 9.9993551e-01 0.0000000e+00]\n",
            "[2.1100942e-04 1.7800856e-05 9.9977118e-01 0.0000000e+00]\n",
            "[9.631123e-14 9.761305e-32 1.000000e+00 0.000000e+00]\n",
            "[1.0000000e+00 7.6657878e-35 2.5042297e-13 0.0000000e+00]\n",
            "[3.918761e-16 0.000000e+00 1.000000e+00 0.000000e+00]\n",
            "[9.9944502e-01 9.5430913e-26 5.5494095e-04 0.0000000e+00]\n",
            "[1.3341582e-28 1.2039403e-16 1.0000000e+00 0.0000000e+00]\n",
            "[5.1572695e-08 0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
            "[6.7955095e-01 1.7766360e-14 3.2044902e-01 0.0000000e+00]\n",
            "[0. 0. 0. 1.]\n",
            "[0.0000000e+00 7.1611176e-30 1.0000000e+00 0.0000000e+00]\n",
            "[0. 0. 0. 1.]\n",
            "[9.8894918e-01 9.7373509e-10 1.1050794e-02 0.0000000e+00]\n",
            "[5.8911421e-13 5.7503805e-18 1.0000000e+00 0.0000000e+00]\n",
            "[2.793896e-19 0.000000e+00 1.000000e+00 0.000000e+00]\n",
            "[1.0000000e+00 0.0000000e+00 1.2823853e-38 0.0000000e+00]\n",
            "[1.6153820e-06 0.0000000e+00 9.9999833e-01 1.8917472e-34]\n",
            "[5.9818864e-12 6.6531130e-29 1.0000000e+00 0.0000000e+00]\n",
            "[1.0000000e+00 2.0212307e-19 2.3842079e-28 0.0000000e+00]\n",
            "[0. 0. 0. 1.]\n",
            "[5.0234705e-14 0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
            "[0. 0. 0. 1.]\n",
            "[1. 0. 0. 0.]\n",
            "[1.05705505e-11 3.22545059e-25 1.00000000e+00 0.00000000e+00]\n",
            "[1.911563e-10 0.000000e+00 1.000000e+00 0.000000e+00]\n",
            "[0. 0. 0. 1.]\n",
            "[9.9148458e-01 2.7952369e-37 8.5154250e-03 0.0000000e+00]\n",
            "[0.000000e+00 0.000000e+00 7.051432e-32 1.000000e+00]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rounded_predictions = np.argmax(predictions, axis=-1)"
      ],
      "metadata": {
        "id": "dWSbcl8zrdM1"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in rounded_predictions:\n",
        "    print(i)"
      ],
      "metadata": {
        "id": "PYv47MB0rgy2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3b352eb-9718-48ad-ac75-4a362593e53d"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "2\n",
            "1\n",
            "3\n",
            "2\n",
            "2\n",
            "0\n",
            "0\n",
            "0\n",
            "2\n",
            "0\n",
            "0\n",
            "3\n",
            "0\n",
            "2\n",
            "0\n",
            "3\n",
            "3\n",
            "2\n",
            "0\n",
            "0\n",
            "2\n",
            "0\n",
            "2\n",
            "0\n",
            "0\n",
            "2\n",
            "2\n",
            "0\n",
            "0\n",
            "3\n",
            "2\n",
            "0\n",
            "3\n",
            "2\n",
            "3\n",
            "2\n",
            "0\n",
            "3\n",
            "3\n",
            "2\n",
            "3\n",
            "2\n",
            "2\n",
            "2\n",
            "0\n",
            "2\n",
            "2\n",
            "2\n",
            "0\n",
            "2\n",
            "0\n",
            "2\n",
            "2\n",
            "0\n",
            "3\n",
            "2\n",
            "3\n",
            "0\n",
            "2\n",
            "2\n",
            "0\n",
            "2\n",
            "2\n",
            "0\n",
            "3\n",
            "2\n",
            "3\n",
            "0\n",
            "2\n",
            "2\n",
            "3\n",
            "0\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Confusion Matrix"
      ],
      "metadata": {
        "id": "Ulih4eeAsTW0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "TQWS_PJ9sWLx"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_true=test_labels, y_pred=rounded_predictions)"
      ],
      "metadata": {
        "id": "ahnF0hGKsXEQ"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "metadata": {
        "id": "MjcQ6gCxsaU7"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm_plot_labels = ['quartile 1','quartile 2', 'quartile 3', 'quartile 4']\n",
        "plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "YgxK1mEfsdOZ",
        "outputId": "c6923944-a818-49a5-b375-8b89af6ec157"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[14  0  7  0]\n",
            " [10  1  9  0]\n",
            " [ 1  0 13  3]\n",
            " [ 0  0  3 13]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analysis of the confusion Matrix\n",
        "\n",
        "It would appear that the house prices that are hardest to predict for the model are the Level 2/4 ones -- not the worst but not good.\n",
        "This is partly a result of the distribution of the data into 4 arbitrary categories. However it is clear that the model can predict the cheapest and most expensive houses with some ease.\n"
      ],
      "metadata": {
        "id": "vz0nhtPZX_eK"
      }
    }
  ]
}